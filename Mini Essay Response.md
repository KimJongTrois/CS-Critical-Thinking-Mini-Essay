# Mini Essay Response

The idea that AI will end up destroying humanity has been toyed with countless times in films, books and the media. Even inventors and innovators, such as Elon Musk, have expressed their concern for AI’s foreboding future, so what is it that makes AI such an incredible yet worrisome threat?

To clear things up for those who are unsure, Machine Learning is a technique used to make a computer better at performing a specified task. Through what can be thousands of iterations, a computer attempts to solve a problem using trial and error, and is rewarded by a separate algorithm (letting the computer know how to be right). By repeating this process over and over again, the computer will create a more refined method to solve the given problem. This technique is called Reinforced Learning, and can be used to make a computer do things that were once considered only doable by humans, such as driving a car. Bearing in mind this idea is relatively new, AI is becoming more widespread and advanced; some examples of where it’s used are in driverless cars, identifying cancer cells, and even in more annoying things like targeted advertising. 

Seeing as AI has this amazing potential to solve complex problems, it’s popularity (as previously mentioned) is rapidly growing. To add to this, there’s a growing amount of research behind Machine Learning, so the possibilities are becoming wider each day. However, this brings us onto our first problem. With AI becoming more widespread, who’s to say what it will be used for. Sure, there are people who want to create wonderful, life changing things, but, looking back through history, there’s always somebody who will use the latest invention/tool to cause harm in some way shape or form. Due to the complexities of an AI, it can be harder to put counter measures in place to protect vulnerable people. Luckily, for the time being, AI is mostly bound to a local computer system or network, and hence has no physical form. Therefore it’s much harder for malicious AI to physically harm someone, but who’s to say in the future, when AI could potentially take a physical form.

The second/main problem with AI ties into the first - since an AI is just a set of algorithms, it has no moral compass, feels no emotions and thus can’t properly tell right from wrong. Well, that’s not entirely true, it can tell right from wrong, but only in context to an agent’s (something that is performing a specified task by acting with its environment) given task . In other words, when it comes to linking the impacts of its task to the rest of the wider world, it’s useless. As established earlier, an AI wants to be rewarded, but with a lot of its learning being based off of a repetitive cycle of trial and error, it’s bound to make mistakes. With an agent wanting to make as little mistakes as possible (and instead to be rewarded) it will often end up finding loopholes that allow it to be rewarded for something that can often be counterproductive. A hypothetical example of this would be a robot whose job is to clean a room - everytime it can’t see anything dirty, it’s rewarded; therefore the robot finds out that there’s an easier way to get rewarded, however it ignores the intent of the programmer. Instead of cleaning the room, the robot puts a bucket over its head. From this example, you can also see how the robot is entirely removed from the real world, to the robot, it’s world is being rewarded for not having any sight, and the only punishment it receives is not from the room being dirty, but from not being rewarded. This raises many concerns for the future of humanity, and although I think it would be a massive oversight for a developer/programmer to give an AI the power to destroy even 1/100th of the world, theoretically, if in some way it was easier for an AI to destroy the world then it most certainly would because without any connection to big, wide world, it has nothing to punish it for making such a catastrophic mistake. It’s only concern is if it is or is not being rewarded, everything else is irrelevant, such as the fate of humanity. This problem can be expanded upon, when you realise that, once again, hypothetically an AI could give itself the power to destroy the world, and wouldn’t need to be given the power from its creation.

Overall, I think that, yes, it would be possible for an AI to destroy humanity, we are not at the stage where a problem is so complicated that global destruction is the easiest method to achieve success. Although there are examples of malicious uses of AI, there are always methods, for instance the creation of a more reinforced punishment system, that can always limit the power an agent has. Machine Learning is relatively new, and people are still uncovering its power. However, it's important to keep in mind that there are people who work on finding solutions to all of the problems above. So, in conclusion, I guess, we’re not doomed?
